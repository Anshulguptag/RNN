{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"wonderland.txt\"\n",
    "raw_text = open(filename).read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  163779\n",
      "Total Vocab:  58\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print (\"Total Characters: \", n_chars)\n",
    "print (\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "\tseq_in = raw_text[i:i + seq_length]\n",
    "\tseq_out = raw_text[i + seq_length]\n",
    "\tdataX.append([char_to_int[char] for char in seq_in])\n",
    "\tdataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  163679\n"
     ]
    }
   ],
   "source": [
    "print (\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / float(n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"C:\\\\Users\\\\anshul\\\\jupyter\\\\RNN\\\\weights\\\\weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "163679/163679 [==============================] - 986s 6ms/step - loss: 2.9862\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.98619, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-01-2.9862.hdf5\n",
      "Epoch 2/80\n",
      "163679/163679 [==============================] - 998s 6ms/step - loss: 2.7979\n",
      "\n",
      "Epoch 00002: loss improved from 2.98619 to 2.79788, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-02-2.7979.hdf5\n",
      "Epoch 3/80\n",
      "163679/163679 [==============================] - 996s 6ms/step - loss: 2.7049\n",
      "\n",
      "Epoch 00003: loss improved from 2.79788 to 2.70492, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-03-2.7049.hdf5\n",
      "Epoch 4/80\n",
      "163679/163679 [==============================] - 990s 6ms/step - loss: 2.6351\n",
      "\n",
      "Epoch 00004: loss improved from 2.70492 to 2.63508, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-04-2.6351.hdf5\n",
      "Epoch 5/80\n",
      "163679/163679 [==============================] - 999s 6ms/step - loss: 2.5764\n",
      "\n",
      "Epoch 00005: loss improved from 2.63508 to 2.57645, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-05-2.5764.hdf5\n",
      "Epoch 6/80\n",
      "163679/163679 [==============================] - 990s 6ms/step - loss: 2.5237\n",
      "\n",
      "Epoch 00006: loss improved from 2.57645 to 2.52375, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-06-2.5237.hdf5\n",
      "Epoch 7/80\n",
      "163679/163679 [==============================] - 994s 6ms/step - loss: 2.4719\n",
      "\n",
      "Epoch 00007: loss improved from 2.52375 to 2.47192, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-07-2.4719.hdf5\n",
      "Epoch 8/80\n",
      "163679/163679 [==============================] - 992s 6ms/step - loss: 2.4248\n",
      "\n",
      "Epoch 00008: loss improved from 2.47192 to 2.42482, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-08-2.4248.hdf5\n",
      "Epoch 9/80\n",
      "163679/163679 [==============================] - 989s 6ms/step - loss: 2.3833\n",
      "\n",
      "Epoch 00009: loss improved from 2.42482 to 2.38326, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-09-2.3833.hdf5\n",
      "Epoch 10/80\n",
      "163679/163679 [==============================] - 988s 6ms/step - loss: 2.3434\n",
      "\n",
      "Epoch 00010: loss improved from 2.38326 to 2.34345, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-10-2.3434.hdf5\n",
      "Epoch 11/80\n",
      "163679/163679 [==============================] - 992s 6ms/step - loss: 2.3055\n",
      "\n",
      "Epoch 00011: loss improved from 2.34345 to 2.30547, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-11-2.3055.hdf5\n",
      "Epoch 12/80\n",
      "163679/163679 [==============================] - 978s 6ms/step - loss: 2.2688\n",
      "\n",
      "Epoch 00012: loss improved from 2.30547 to 2.26882, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-12-2.2688.hdf5\n",
      "Epoch 13/80\n",
      "163679/163679 [==============================] - 975s 6ms/step - loss: 2.2368\n",
      "\n",
      "Epoch 00013: loss improved from 2.26882 to 2.23677, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-13-2.2368.hdf5\n",
      "Epoch 14/80\n",
      "163679/163679 [==============================] - 991s 6ms/step - loss: 2.2023\n",
      "\n",
      "Epoch 00014: loss improved from 2.23677 to 2.20231, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-14-2.2023.hdf5\n",
      "Epoch 15/80\n",
      "163679/163679 [==============================] - 988s 6ms/step - loss: 2.1722\n",
      "\n",
      "Epoch 00015: loss improved from 2.20231 to 2.17225, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-15-2.1722.hdf5\n",
      "Epoch 16/80\n",
      "163679/163679 [==============================] - 986s 6ms/step - loss: 2.1391\n",
      "\n",
      "Epoch 00016: loss improved from 2.17225 to 2.13907, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-16-2.1391.hdf5\n",
      "Epoch 17/80\n",
      "163679/163679 [==============================] - 990s 6ms/step - loss: 2.1148\n",
      "\n",
      "Epoch 00017: loss improved from 2.13907 to 2.11480, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-17-2.1148.hdf5\n",
      "Epoch 18/80\n",
      "163679/163679 [==============================] - 993s 6ms/step - loss: 2.0894\n",
      "\n",
      "Epoch 00018: loss improved from 2.11480 to 2.08939, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-18-2.0894.hdf5\n",
      "Epoch 19/80\n",
      "163679/163679 [==============================] - 992s 6ms/step - loss: 2.0648\n",
      "\n",
      "Epoch 00019: loss improved from 2.08939 to 2.06481, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-19-2.0648.hdf5\n",
      "Epoch 20/80\n",
      "163679/163679 [==============================] - 1009s 6ms/step - loss: 2.0397\n",
      "\n",
      "Epoch 00020: loss improved from 2.06481 to 2.03973, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-20-2.0397.hdf5\n",
      "Epoch 21/80\n",
      "163679/163679 [==============================] - 982s 6ms/step - loss: 2.0194\n",
      "\n",
      "Epoch 00021: loss improved from 2.03973 to 2.01941, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-21-2.0194.hdf5\n",
      "Epoch 22/80\n",
      "163679/163679 [==============================] - 987s 6ms/step - loss: 1.9970\n",
      "\n",
      "Epoch 00022: loss improved from 2.01941 to 1.99699, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-22-1.9970.hdf5\n",
      "Epoch 23/80\n",
      "163679/163679 [==============================] - 969s 6ms/step - loss: 1.9800\n",
      "\n",
      "Epoch 00023: loss improved from 1.99699 to 1.97998, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-23-1.9800.hdf5\n",
      "Epoch 24/80\n",
      "163679/163679 [==============================] - 982s 6ms/step - loss: 1.9635\n",
      "\n",
      "Epoch 00024: loss improved from 1.97998 to 1.96354, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-24-1.9635.hdf5\n",
      "Epoch 25/80\n",
      "163679/163679 [==============================] - 985s 6ms/step - loss: 1.9447\n",
      "\n",
      "Epoch 00025: loss improved from 1.96354 to 1.94472, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-25-1.9447.hdf5\n",
      "Epoch 26/80\n",
      "163679/163679 [==============================] - 1593s 10ms/step - loss: 1.9308\n",
      "\n",
      "Epoch 00026: loss improved from 1.94472 to 1.93077, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-26-1.9308.hdf5\n",
      "Epoch 27/80\n",
      "163679/163679 [==============================] - 1699s 10ms/step - loss: 1.9159\n",
      "\n",
      "Epoch 00027: loss improved from 1.93077 to 1.91592, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-27-1.9159.hdf5\n",
      "Epoch 28/80\n",
      "163679/163679 [==============================] - 1207s 7ms/step - loss: 1.8970\n",
      "\n",
      "Epoch 00028: loss improved from 1.91592 to 1.89699, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-28-1.8970.hdf5\n",
      "Epoch 29/80\n",
      "163679/163679 [==============================] - 1092s 7ms/step - loss: 1.8839\n",
      "\n",
      "Epoch 00029: loss improved from 1.89699 to 1.88388, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-29-1.8839.hdf5\n",
      "Epoch 30/80\n",
      "163679/163679 [==============================] - 1035s 6ms/step - loss: 1.8736\n",
      "\n",
      "Epoch 00030: loss improved from 1.88388 to 1.87364, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-30-1.8736.hdf5\n",
      "Epoch 31/80\n",
      "163679/163679 [==============================] - 1002s 6ms/step - loss: 1.8604\n",
      "\n",
      "Epoch 00031: loss improved from 1.87364 to 1.86041, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-31-1.8604.hdf5\n",
      "Epoch 32/80\n",
      "163679/163679 [==============================] - 1003s 6ms/step - loss: 1.8495\n",
      "\n",
      "Epoch 00032: loss improved from 1.86041 to 1.84954, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-32-1.8495.hdf5\n",
      "Epoch 33/80\n",
      "163679/163679 [==============================] - 969s 6ms/step - loss: 1.8386\n",
      "\n",
      "Epoch 00033: loss improved from 1.84954 to 1.83858, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-33-1.8386.hdf5\n",
      "Epoch 34/80\n",
      "163679/163679 [==============================] - 1009s 6ms/step - loss: 1.8251\n",
      "\n",
      "Epoch 00034: loss improved from 1.83858 to 1.82510, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-34-1.8251.hdf5\n",
      "Epoch 35/80\n",
      "163679/163679 [==============================] - 1487s 9ms/step - loss: 1.8170\n",
      "\n",
      "Epoch 00035: loss improved from 1.82510 to 1.81701, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-35-1.8170.hdf5\n",
      "Epoch 36/80\n",
      "163679/163679 [==============================] - 1434s 9ms/step - loss: 1.8093\n",
      "\n",
      "Epoch 00036: loss improved from 1.81701 to 1.80929, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-36-1.8093.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/80\n",
      "163679/163679 [==============================] - 1328s 8ms/step - loss: 1.7965\n",
      "\n",
      "Epoch 00037: loss improved from 1.80929 to 1.79648, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-37-1.7965.hdf5\n",
      "Epoch 38/80\n",
      "163679/163679 [==============================] - 1376s 8ms/step - loss: 1.7879\n",
      "\n",
      "Epoch 00038: loss improved from 1.79648 to 1.78788, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-38-1.7879.hdf5\n",
      "Epoch 39/80\n",
      "163679/163679 [==============================] - 1543s 9ms/step - loss: 1.7768\n",
      "\n",
      "Epoch 00039: loss improved from 1.78788 to 1.77678, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-39-1.7768.hdf5\n",
      "Epoch 40/80\n",
      "163679/163679 [==============================] - 1298s 8ms/step - loss: 1.7705\n",
      "\n",
      "Epoch 00040: loss improved from 1.77678 to 1.77045, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-40-1.7705.hdf5\n",
      "Epoch 41/80\n",
      "163679/163679 [==============================] - 1110s 7ms/step - loss: 1.7622\n",
      "\n",
      "Epoch 00041: loss improved from 1.77045 to 1.76215, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-41-1.7622.hdf5\n",
      "Epoch 42/80\n",
      "163679/163679 [==============================] - 1119s 7ms/step - loss: 1.7590\n",
      "\n",
      "Epoch 00042: loss improved from 1.76215 to 1.75897, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-42-1.7590.hdf5\n",
      "Epoch 43/80\n",
      "163679/163679 [==============================] - 1082s 7ms/step - loss: 1.7476\n",
      "\n",
      "Epoch 00043: loss improved from 1.75897 to 1.74760, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-43-1.7476.hdf5\n",
      "Epoch 44/80\n",
      "163679/163679 [==============================] - 1175s 7ms/step - loss: 1.7432\n",
      "\n",
      "Epoch 00044: loss improved from 1.74760 to 1.74322, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-44-1.7432.hdf5\n",
      "Epoch 45/80\n",
      "163679/163679 [==============================] - 1463s 9ms/step - loss: 1.7314\n",
      "\n",
      "Epoch 00045: loss improved from 1.74322 to 1.73140, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-45-1.7314.hdf5\n",
      "Epoch 46/80\n",
      "163679/163679 [==============================] - 1019s 6ms/step - loss: 1.7258\n",
      "\n",
      "Epoch 00046: loss improved from 1.73140 to 1.72583, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-46-1.7258.hdf5\n",
      "Epoch 47/80\n",
      "163679/163679 [==============================] - 1029s 6ms/step - loss: 1.7238\n",
      "\n",
      "Epoch 00047: loss improved from 1.72583 to 1.72375, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-47-1.7238.hdf5\n",
      "Epoch 48/80\n",
      "163679/163679 [==============================] - 1024s 6ms/step - loss: 1.7196\n",
      "\n",
      "Epoch 00048: loss improved from 1.72375 to 1.71959, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-48-1.7196.hdf5\n",
      "Epoch 49/80\n",
      "163679/163679 [==============================] - 1008s 6ms/step - loss: 1.7091\n",
      "\n",
      "Epoch 00049: loss improved from 1.71959 to 1.70912, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-49-1.7091.hdf5\n",
      "Epoch 50/80\n",
      "163679/163679 [==============================] - 1019s 6ms/step - loss: 1.6989\n",
      "\n",
      "Epoch 00050: loss improved from 1.70912 to 1.69889, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-50-1.6989.hdf5\n",
      "Epoch 51/80\n",
      "163679/163679 [==============================] - 1299s 8ms/step - loss: 1.6918\n",
      "\n",
      "Epoch 00051: loss improved from 1.69889 to 1.69177, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-51-1.6918.hdf5\n",
      "Epoch 52/80\n",
      "163679/163679 [==============================] - 1365s 8ms/step - loss: 1.6875\n",
      "\n",
      "Epoch 00052: loss improved from 1.69177 to 1.68750, saving model to C:\\Users\\anshul\\jupyter\\RNN\\weights\\weights-improvement-52-1.6875.hdf5\n",
      "Epoch 53/80\n",
      "163679/163679 [==============================] - 1314s 8ms/step - loss: 1.6899\n",
      "\n",
      "Epoch 00053: loss did not improve\n",
      "Epoch 54/80\n",
      "  4352/163679 [..............................] - ETA: 24:41 - loss: 1.6185"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-4b2e18445f74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 778\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 982\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1032\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1037\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=80, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"weights-improvement-20-2.1271.hdf5\"\n",
    "model.load_weights(\"C:\\\\Users\\\\anshul\\\\jupyter\\\\RNN\\\\weights\"+str(filename))\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "sentence=\"d herself lying on the bank, with her head in the lap of her sister, who was gently brushing away so\"\n",
    "sentence=sentence.lower()\n",
    "x1=[char_to_int[value] for value in sentence]\n",
    "pattern = x1\n",
    "print (\"Seed:\")\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "# generate characters\n",
    "print(\"-------\")\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print (\"\\nDone.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
